import streamlit as st
import time
import os
import google.generativeai as genai
from dotenv import load_dotenv

# 1. SAYFA AYARLARI (Mutlaka en Ã¼stte olmalÄ±)
st.set_page_config(page_title="T.C. Anayasa AI", layout="wide", page_icon="âš–ï¸")

# 2. YAPILANDIRMA VE API BAÄLANTISI
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

if api_key:
    genai.configure(api_key=api_key)
    # Sadece 'gemini-1.5-flash' yerine tam yolu yazÄ±yoruz:
    model = genai.GenerativeModel(model_name="models/gemini-1.5-flash")
else:
    st.error("âš ï¸ API Key bulunamadÄ±! LÃ¼tfen Secrets veya .env dosyasÄ±nÄ± kontrol edin.")

# 3. SOL PANEL (SIDEBAR)
with st.sidebar:
    st.title("ğŸ“‚ Dava DosyasÄ± YÃ¼kle")
    st.info("Analiz edilecek iddianame veya kararÄ± buraya yÃ¼kleyin.")
    uploaded_file = st.file_uploader("Dosya SeÃ§ (PDF/TXT)", type=["pdf", "txt"])
    
    if uploaded_file:
        with st.status("DokÃ¼man analiz ediliyor...", expanded=True) as status:
            st.write("Metinler ayÄ±klanÄ±yor...")
            time.sleep(1)
            st.write("VektÃ¶r veritabanÄ±na taranÄ±yor...")
            time.sleep(1)
            status.update(label="Analiz TamamlandÄ±!", state="complete", expanded=False)
        st.success(f"âœ… {uploaded_file.name} hazÄ±r.")
    
    st.divider()
    st.write("ğŸ”§ Model AyarlarÄ±")
    # Bu deÄŸiÅŸkeni Gemini'ye gÃ¶nderirken kullanabilirsin
    temp = st.slider("Yorum EsnekliÄŸi (Temperature)", 0.0, 1.0, 0.3)

# 4. ANA EKRAN (CHAT ARA YÃœZÃœ)
st.title("âš–ï¸ T.C. Anayasal Muhakeme AsistanÄ±")

# Mesaj geÃ§miÅŸini baÅŸlat (Session State)
if "messages" not in st.session_state:
    st.session_state.messages = []

# Eski mesajlarÄ± ekrana bas
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. KULLANICI GÄ°RDÄ°SÄ° VE CEVAP SÃœRECÄ°
if prompt := st.chat_input("Hukuki sorunuzu veya vaka Ã¶zetini girin..."):
    # KullanÄ±cÄ± mesajÄ±nÄ± gÃ¶ster ve kaydet
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ASÄ°STAN CEVABI (GERÃ‡EK ZAMANLI)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # Gemini modelinden yanÄ±t al
            # Not: Ä°stersen 'generation_config' ile slider'dan gelen 'temp' deÄŸerini buraya ekleyebilirsin
            response = model.generate_content(prompt)
            actual_response = response.text
            
            # Daktilo efekti simÃ¼lasyonu
            for chunk in actual_response.split():
                full_response += chunk + " "
                time.sleep(0.05)
                message_placeholder.markdown(full_response + "â–Œ")
            
            # Final cevabÄ± gÃ¶ster
            message_placeholder.markdown(full_response)
            
        except Exception as e:
            error_message = f"Bir hata oluÅŸtu: {str(e)}"
            st.error(error_message)
            full_response = error_message
    
    # Asistan cevabÄ±nÄ± geÃ§miÅŸe kaydet
    st.session_state.messages.append({"role": "assistant", "content": full_response})